---
external help file: powershai-help.xml
schema: 2.0.0
powershai: true
---

# Get-AiChat

## SYNOPSIS <!--!= @#Synop !-->
Sends messages to an LLM and returns the response

## DESCRIPTION <!--!= @#Desc !-->
This is the most basic Chat method provided by PowershAI.  
With this function, you can send a message to an LLM from the current provider.  

This function is a lower-level, standardized way to access an LLM that powershai provides.  
It does not manage history or context. It is useful for invoking simple prompts that do not require multiple interactions as in a Chat. 
Although it supports Function Calling, it does not execute any code, and only returns the model's response.



** INFORMATION FOR PROVIDERS

The provider must implement the Chat function for this functionality to be available. 
The chat function must return an object with the response with the same specification as the OpenAI, Chat Completion function.
The following links serve as a basis:

https://platform.openai.com/docs/guides/chat-completions
https://platform.openai.com/docs/api-reference/chat/object (return without streaming)
The provider must implement the parameters of this function. 
See the documentation for each parameter for details and how to map to a provider;

When the model does not support one of the informed parameters (that is, there is no equivalent functionality, or that can be implemented in an equivalent way) an error should be returned.
Parameters that are not passed to the provider will have a description informing!

## SYNTAX <!--!= @#Syntax !-->

```
Get-AiChat [[-prompt] <Object>] [[-temperature] <Object>] [[-model] <Object>] [[-MaxTokens] <Object>] [[-ResponseFormat] <Object>] [[-Functions] <Object>] [[-RawParams] <Object>] 
[[-StreamCallback] <Object>] [-IncludeRawResp] [[-Check] <Object>] [[-Retries] <Object>] [-ContentOnly] [[-ProviderRawParams] <Object>] [<CommonParameters>]
```

## PARAMETERS <!--!= @#Params !-->

### -prompt
The prompt to be sent. Must be in the format described by the ConvertTo-OpenaiMessage function

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 1
Default Value: 
Accept pipeline input: false
Accept wildcard characters: false
```

### -temperature
Model temperature

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 2
Default Value: 0.6
Accept pipeline input: false
Accept wildcard characters: false
```

### -model
Model name. If not specified, uses the provider's default.

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 3
Default Value: 
Accept pipeline input: false
Accept wildcard characters: false
```

### -MaxTokens
Maximum tokens to be returned

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 4
Default Value: 1024
Accept pipeline input: false
Accept wildcard characters: false
```

### -ResponseFormat
Response format
Acceptable formats, and behavior, should follow the same as OpenAI: https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format
Shortcuts:

"json"|"json_object", is equivalent to {"type": "json_object"}
object must specify a schema as if it were passed directly to the Openai API, in the response_format.json_schema field

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 5
Default Value: 
Accept pipeline input: false
Accept wildcard characters: false
```

### -Functions
List of tools that should be invoked!
You can use commands like Get-OpenaiTool*, to easily transform powershell functions into the expected format!
If the model invokes the function, the response, both in stream and normal, must also follow the OpenAI tool calling model.
This parameter must follow the same schema as the OpenAI Function Calling: https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 6
Default Value: @()
Accept pipeline input: false
Accept wildcard characters: false
```

### -RawParams
Specify direct parameters from the provider's API.
This will overwrite the values that were calculated and generated based on the other parameters.

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 7
Default Value: @{}
Accept pipeline input: false
Accept wildcard characters: false
```

### -StreamCallback
Enables Stream mode
You must specify a ScriptBlock that will be invoked for each text generated by the LLM.
The script must receive a parameter that represents each segment, in the same streaming format returned
This parameter is an object that will contain the choices property, which is in the same schema returned by OpenAI streaming:
https://platform.openai.com/docs/api-reference/chat/streaming

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 8
Default Value: 
Accept pipeline input: false
Accept wildcard characters: false
```

### -IncludeRawResp
Include the API response in a field called IncludeRawResp
The following parameter is not passed to the provider!

```yml
Parameter Set: (All)
Type: SwitchParameter
Aliases: 
Accepted Values: 
Required: false
Position: named
Default Value: False
Accept pipeline input: false
Accept wildcard characters: false
```

### -Check
Validates the response and if it is not as expected, tries again!
Can be a string or a scriptblock
It is not passed to the provider!

```yml
Parameter Set: (All)
Type: Object
Aliases: CheckLike,CheckRegex,CheckJson
Accepted Values: 
Required: false
Position: 9
Default Value: 
Accept pipeline input: false
Accept wildcard characters: false
```

### -Retries
Max attempts if Check fails
It is not passed to the provider!

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 10
Default Value: 1
Accept pipeline input: false
Accept wildcard characters: false
```

### -ContentOnly
Returns only the text of the response.
It is not passed to the provider!

```yml
Parameter Set: (All)
Type: SwitchParameter
Aliases: 
Accepted Values: 
Required: false
Position: named
Default Value: False
Accept pipeline input: false
Accept wildcard characters: false
```

### -ProviderRawParams
Specifies raw params per provider. This takes precedence over -RawParams (if 2 parameters with the same name (and path) are specified).
You must specify a hashtable and each key is the provider name. Then, the value of each key is the same as you would specify in -RawParams.

```yml
Parameter Set: (All)
Type: Object
Aliases: 
Accepted Values: 
Required: false
Position: 11
Default Value: @{}
Accept pipeline input: false
Accept wildcard characters: false
```


<!--PowershaiAiDocBlockStart-->
_Automatically translated using PowershAI and AI
_
<!--PowershaiAiDocBlockEnd-->
